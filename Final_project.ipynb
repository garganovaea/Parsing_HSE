{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проверка структуры сайта в целом. Русскоязычные страницы.\n",
    "Общее время: около 35-40 минут (в зависимости от стабильности интернет соединения)\n",
    "\n",
    "Подсчет количества знаков в **каждой** полученной ссылке: 2 часа 45 минут и более  \n",
    "\n",
    "Производится переход по каждой ссылке (то есть по всем ссылкам на академических руководителей всех ОП, на всех менеджеров и тд), чтобы удостовериться, что страницы заполнены. Поэтому этот подсчет длится дольше всех.\n",
    " \n",
    "**Партнеры** встречаются и в Общих разделах и в разделе Главное. В Общих: названия, в Главном: ссылки.  \n",
    "**О программе** встречается и в Общих разделах и в разделе Главное. В Общих: количество символов, в Главном: ссылки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as rq\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создадим результирующую таблицу и заполним основную информацию о программах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(columns=['Наименование ОП', 'Уровень обучения',\n",
    "                               'Подразделение', 'Ссылка на сайт'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def soup_d(html):\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    url = 'https://www.hse.ru/education/bachelor/'\n",
    "    html = rq.get(url).text\n",
    "    soup = soup_d(html)\n",
    "    text = soup.findAll(\n",
    "        'div', {'class': 'b-row__item b-row__item--6 b-row__item--t12'})\n",
    "    quantity = range(len(text))\n",
    "\n",
    "    # Выгрузим ссылки на все ОП\n",
    "\n",
    "    urls = [text[i].contents[0].get('href') for i in quantity]\n",
    "\n",
    "    # Заменим нестандартные страницы школы дизайна\n",
    "    urls[urls.index('https://design.hse.ru/ba/program/design')\n",
    "         ] = 'https://www.hse.ru/ba/design/'\n",
    "    urls[urls.index('https://design.hse.ru/ba/program/fashion')\n",
    "         ] = 'https://www.hse.ru/ba/moda/'\n",
    "    urls[urls.index('https://art.hse.ru/ba')\n",
    "         ] = 'https://www.hse.ru/ba/art/'\n",
    "    urls[urls.index('http://design.hse.ru/mag-design')\n",
    "         ] = 'https://www.hse.ru/ma/cd/'\n",
    "    urls[urls.index('https://design.hse.ru/ma/program/interior')\n",
    "         ] = 'https://www.hse.ru/ma/idesign/'\n",
    "    urls[urls.index('http://design.hse.ru/mag-comm')\n",
    "         ] = 'https://www.hse.ru/ma/designcom/'\n",
    "    urls[urls.index('http://design.hse.ru/mag-fashion')\n",
    "         ] = 'https://www.hse.ru/ma/fashion/'\n",
    "    urls[urls.index('http://art.hse.ru/ma')\n",
    "         ] = 'https://www.hse.ru/ma/contart/'\n",
    "    urls[urls.index('http://design.hse.ru/pages/184')\n",
    "         ] = 'https://www.hse.ru/ma/moddis/'\n",
    "\n",
    "    # Удалим еще не открытую программу\n",
    "    urls.remove('https://www.hse.ru/ma/digitalpm/')\n",
    "\n",
    "    result['Ссылка на сайт'] = urls\n",
    "\n",
    "    # Названия ОП\n",
    "    names = [text[i].contents[0].contents[0] for i in quantity]\n",
    "    names.remove('Управление цифровым продуктом')  # Не открыта\n",
    "    result['Наименование ОП'] = names\n",
    "\n",
    "    # Уровень обучения\n",
    "    bac_q = names.index('Фундаментальная и прикладная лингвистика')+1\n",
    "    mag_q = len(names)-bac_q\n",
    "    d_edu = ['Бак']*bac_q + ['Маг']*mag_q\n",
    "    result['Уровень обучения'] = d_edu\n",
    "\n",
    "    # Подразделения\n",
    "    faculties = [text[i].contents[1].contents[1].contents[0]\n",
    "                 for i in quantity]\n",
    "    faculties.remove('Высшая школа бизнеса')  # Не открыта\n",
    "    result['Подразделение'] = faculties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Перейдем к проверке наличия требуемых блоков на сайтах ОП**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Общие разделы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для парсинга одной ссылки из одного блока\n",
    "\n",
    "def pars_url(tag, attribute, soup):\n",
    "    text = soup.find(tag, {\"class\": attribute})\n",
    "    if text is None:\n",
    "        url = 'Нет'\n",
    "    else:\n",
    "        url = text.contents[0].get('href')\n",
    "        if len(url) is 0:\n",
    "            url = 'Нет'\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для парсинга нескольких ссылок из одного блока\n",
    "\n",
    "def pars_url_list(tag, attribute, soup):\n",
    "    text = soup.find(tag, {\"class\": attribute})\n",
    "    if text is None:\n",
    "        url = 'Нет'\n",
    "    else:\n",
    "        url = []\n",
    "        for i in range(len(text)):\n",
    "            text_2 = text.contents[i]\n",
    "            while text_2.get('href') == None:\n",
    "                text_2 = text_2.contents[0]\n",
    "            url.append(text_2.get('href'))\n",
    "    if len(url) is 0:\n",
    "        url = 'Нет'\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для парсинга языка обучения\n",
    "\n",
    "def language(content):\n",
    "    lang = []\n",
    "    for i in range(len(content)):\n",
    "        if len(content[i]) >= 2:\n",
    "            lang.append('ENG_RUS')\n",
    "        elif len(content[i]) == 1:\n",
    "            lang.append(content[i][0].text)\n",
    "        else:\n",
    "            lang.append('Не указано')\n",
    "    return lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для определения на какой раздел указывают ссылки, спарсенные с помощью pars_url_list\n",
    "\n",
    "def blocks(nav, part):\n",
    "    block = []\n",
    "    for i in range(len(nav)):\n",
    "        b = 0\n",
    "        for j in range(len(nav[i])):\n",
    "            if (nav[i][j] == result['Ссылка на сайт'][i] + part):\n",
    "                b = nav[i][j]\n",
    "        if b == 0:\n",
    "            block.append('Нет')\n",
    "        else:\n",
    "            block.append(b)\n",
    "    return block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для парсинга текстов нескольких элементов из одного блока\n",
    "\n",
    "def pars_text_list(tag, attribute, soup):\n",
    "    text = soup.find(tag, {\"class\": attribute})\n",
    "    if text is None:\n",
    "        position = 'Нет'\n",
    "    else:\n",
    "        position = []\n",
    "        for i in range(len(text)):\n",
    "            position.append(text.contents[i].contents[1].text)\n",
    "    if len(position) is 0:\n",
    "        position = 'Нет'\n",
    "    return position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для парсинга руководителей\n",
    "\n",
    "def persons(pers_url, pers_name):\n",
    "    ac_supervisor = []\n",
    "    manager = []\n",
    "    for i in range(len(pers_url)):\n",
    "        if pers_url[i] == 'Нет':\n",
    "            ac_supervisor.append('Нет')\n",
    "            manager.append('Нет')\n",
    "        else:\n",
    "            a = 0\n",
    "            m = 0\n",
    "            for j in range(len(pers_name[i])):\n",
    "                if (pers_name[i][j] == 'Академический руководитель') or (pers_name[i][j] == 'Руководитель'):\n",
    "                    a = 'https:'+pers_url[i][j]\n",
    "                if (pers_name[i][j] == 'Менеджер'):\n",
    "                    m = 'https:'+pers_url[i][j]\n",
    "            if a != 0:\n",
    "                ac_supervisor.append(a)\n",
    "            else:\n",
    "                ac_supervisor.append('Нет')\n",
    "            if m != 0:\n",
    "                manager.append(m)\n",
    "            else:\n",
    "                manager.append('Нет')\n",
    "    return [ac_supervisor, manager]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для парсинга учебного офиса\n",
    "\n",
    "def st_office(tag, attribute, soup):\n",
    "    text = soup.findAll(tag, {\"class\": attribute})\n",
    "    if text is None:\n",
    "        url = 'Нет'\n",
    "    else:\n",
    "        index = 'no'\n",
    "        for i in range(len(text)):\n",
    "            if (text[i].text == 'Учебный офис'):\n",
    "                index = i\n",
    "                break\n",
    "        if index == 'no':\n",
    "            url = 'Нет'\n",
    "        else:\n",
    "            t = text[index]\n",
    "            while t.get('href') == None:\n",
    "                t = t.contents[0]\n",
    "            url = t.get('href')\n",
    "    if len(url) is 0:\n",
    "        url = 'Нет'\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для парсинга адреса\n",
    "\n",
    "def address(tag, attribute, soup):\n",
    "    text = soup.findAll(tag, {\"class\": attribute})\n",
    "    if text is None:\n",
    "        return 'Нет'\n",
    "    else:\n",
    "        for i in range(len(text)):\n",
    "            ad = re.search(\n",
    "                r'(\\d{6})|(бульвар)|(ул.)|(наб.)|(просп.)', text[i].text)\n",
    "            if ad is None:\n",
    "                continue\n",
    "            else:\n",
    "                return 'Есть адрес'\n",
    "        return 'Нет'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Телефон\n",
    "\n",
    "def tel(tag, attribute, soup):\n",
    "    text = soup.findAll(tag, {\"class\": attribute})\n",
    "    if text is None:\n",
    "        return 'Нет'\n",
    "    else:\n",
    "        for i in range(len(text)):\n",
    "            t = re.search(\n",
    "                r'((8|\\+7)[\\- ]?)?(\\(?\\d{3}\\)?[\\- ]?)?[\\d\\- ]{7,10}', re.sub(r' ', '', text[i].text))\n",
    "            if t is None:\n",
    "                continue\n",
    "            else:\n",
    "                return t.group(0)\n",
    "        return 'Нет'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# E-mail\n",
    "\n",
    "def mail(tag, attribute, soup):\n",
    "    text = soup.findAll(tag, {\"class\": attribute})\n",
    "    if text is None:\n",
    "        return 'Нет'\n",
    "    else:\n",
    "        for i in range(len(text)):\n",
    "            m = re.search(r'([a-z0-9_-]+\\.)*[a-z0-9_-]+@hse.ru', text[i].text)\n",
    "            if m is None:\n",
    "                continue\n",
    "            else:\n",
    "                return m.group(0)\n",
    "        return 'Нет'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Основная функция для выгрузки общих разделов:**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "soups = []\n",
    "\n",
    "\n",
    "def common_info():\n",
    "\n",
    "    # Теперь найдем soup для всех ОП, чтобы далее к ним обращаться\n",
    "    for url in result['Ссылка на сайт']:\n",
    "        html = rq.get(url).text\n",
    "        soups.append(soup_d(html))\n",
    "\n",
    "    # Язык обучения\n",
    "    content = [soup.findAll(\n",
    "        \"span\", {\"class\": 'b-program__lang'}) for soup in soups]\n",
    "    result['Язык обучения'] = language(content)\n",
    "\n",
    "    navigation = [pars_url_list(\"ul\", 'navigation icon_set1', soup) for soup in soups]\n",
    "\n",
    "    result['Учебные курсы'] = blocks(navigation, part='courses')\n",
    "\n",
    "    result['Преподаватели'] = blocks(navigation, part='tutors')\n",
    "\n",
    "    result['Число студентов и вакантные места'] = blocks(navigation, part='vacant')\n",
    "\n",
    "    result['Документы образовательной программы'] = blocks(navigation, part='documents')\n",
    "\n",
    "    result['Расписание'] = blocks(navigation, part='timetable')\n",
    "\n",
    "    result['День открытых дверей'] = [pars_url(\"div\", 'g-day__desc', soup) for soup in soups]\n",
    "\n",
    "    result['Академический совет'] = blocks(navigation, part='academ_council')\n",
    "\n",
    "    # Академ руководитель и менеджер\n",
    "\n",
    "    # Возьмем все ссылки и названия должностей\n",
    "    pers_url = [pars_url_list(\"div\", 'b-program__side-persons-group', soup) for soup in soups]\n",
    "    pers_name = [pars_text_list(\"div\", 'b-program__side-persons-group', soup) for soup in soups]\n",
    "    pers = persons(pers_url, pers_name)\n",
    "    result['Академический руководитель'] = pers[0]\n",
    "    result['Менеджер'] = pers[1]\n",
    "    # Одна программа указала Академ руководителя в другом блоке:\n",
    "    index = result.loc[result['Ссылка на сайт'] ==\n",
    "                       'https://www.hse.ru/ma/intercomp/'].index\n",
    "    result.loc[index, 'Академический руководитель'] = 'https://www.hse.ru/org/persons/7529224'\n",
    "\n",
    "    result['Учебный офис'] = [st_office(\"div\", 'b-program__side-info with-indent4', soup) for soup in soups]\n",
    "\n",
    "    result['Адрес'] = [address(\"div\", 'b-program__side-info with-indent4', soup) for soup in soups]\n",
    "\n",
    "    # Телефон (некоторые прораммы указывают телефон не в контактах, а как ссылку на\n",
    "    # кнопку, дающую возможность звонить сразу с сайта, дополним список такими номерами)\n",
    "    telephone = [tel(\"div\", 'b-program__side-info with-indent4', soup) for soup in soups]\n",
    "    dop_tel = [tel(\"a\", 'button button_clean_red roistat-phone', soup) for soup in soups]\n",
    "    for i in range(len(soups)):\n",
    "        if (telephone[i] == 'Нет') and (dop_tel[i] != 'Нет'):\n",
    "            telephone[i] = dop_tel[i]\n",
    "    result['Телефон'] = telephone\n",
    "\n",
    "    result['E-mail'] = [mail(\"div\", 'b-program__side-info with-indent4', soup) for soup in soups]\n",
    "\n",
    "    # Запишем файл\n",
    "    result.to_excel(\"Общие разделы.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Основные разделы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_2 = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выгрузка **кратких реквизитов программы**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Продолжительность обучения\n",
    "def duration(tag, attribute, soup):\n",
    "    text = soup.findAll(tag, {\"class\": attribute})\n",
    "    if len(text) > 0:\n",
    "        duration = ' Нет'\n",
    "        for i in range(len(text)):\n",
    "            for j in range(len(text[i])):\n",
    "                t = text[i].contents[j].text\n",
    "                if re.search(r'(года)|(лет)', t) is None:\n",
    "                    continue\n",
    "                else:\n",
    "                    duration = re.sub(r'[\\n]+', '', t)\n",
    "                    duration = re.sub(r' ', '', duration)\n",
    "                    duration = re.sub(r'\\xa0', ' ', duration)\n",
    "                    break\n",
    "    else:\n",
    "        duration = ' Нет'\n",
    "    return duration\n",
    "\n",
    "\n",
    "# Форма обучения\n",
    "def form(tag, attribute, soup):\n",
    "    text = soup.findAll(tag, {\"class\": attribute})\n",
    "    if len(text) > 0:\n",
    "        form = 'Нет'\n",
    "        for i in range(len(text)):\n",
    "            for j in range(len(text[i])):\n",
    "                t = text[i].contents[j].text\n",
    "                if re.search(r'форма', t) is None:\n",
    "                    continue\n",
    "                else:\n",
    "                    form = re.search(\n",
    "                        r'(очная)|(Очная)|(очно-заочная)|(Очно-заочная)|(заочная)|(Заочная)', t).group(0)\n",
    "    else:\n",
    "        form = 'Нет'\n",
    "    return form\n",
    "\n",
    "\n",
    "# Количество бюджетных и платных мест\n",
    "def budget_paid(tag, attribute, soup):\n",
    "    text = soup.findAll(tag, {\"class\": attribute})\n",
    "    if len(text) > 0:\n",
    "        budget = 'Нет'\n",
    "        paid = 'Нет'\n",
    "        for i in range(len(text)):\n",
    "            for j in range(len(text[i])):\n",
    "                t = text[i].contents[j].text\n",
    "                if re.search(r'мест', t) is None:\n",
    "                    continue\n",
    "                else:\n",
    "                    t = re.sub(r'мест', '', t).split()\n",
    "                    for i in range(len(t)):\n",
    "                        if t[i] == 'бюджетных':\n",
    "                            budget = re.sub(r'ВШЭ', '', t[i-1]) + ' мест'\n",
    "                            break\n",
    "                    for i in range(len(t)):\n",
    "                        if t[i] == 'платных':\n",
    "                            paid = re.sub(r'ВШЭ', '', t[i-1]) + ' мест'\n",
    "                            break\n",
    "    else:\n",
    "        budget = 'Нет'\n",
    "        paid = 'Нет'\n",
    "    return [budget, paid]\n",
    "\n",
    "\n",
    "# Аккредитация\n",
    "def accred(tag, attribute, soup):\n",
    "    text = soup.findAll(tag, {\"class\": attribute})\n",
    "    if len(text) > 0:\n",
    "        for i in range(len(text)):\n",
    "            accred = text[i].text\n",
    "            if re.search(r'аккредитация', accred) is None:\n",
    "                accred = 'Нет'\n",
    "            else:\n",
    "                accred = re.sub(r'\\n', '', accred)\n",
    "                # Создаем список на случай, если их несколько:\n",
    "                accred = re.sub(r'аккредитация', '', accred)\n",
    "    else:\n",
    "        accred = 'Нет'\n",
    "    return accred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Базовая информация о программе (аннотация, количество знаков)\n",
    "\n",
    "def annot(tag, attribute1, attribute2, soup):\n",
    "    text = soup.findAll(tag, {\"class\": attribute1})\n",
    "    if len(text) == 0:\n",
    "        text = soup.findAll(tag, {\"class\": attribute2})\n",
    "        if len(text) == 0:           \n",
    "            return 'Нет'\n",
    "        else:\n",
    "            text = text[0].text\n",
    "            length = len(text)\n",
    "            return length\n",
    "    else:\n",
    "        text = text[0].text\n",
    "        length = len(text)\n",
    "        return length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Партнеры\n",
    "\n",
    "def partns(tag, attribute, soup):\n",
    "    text = soup.findAll(tag, {\"class\": attribute})\n",
    "    if len(text) == 0:\n",
    "        return 'Нет'\n",
    "    else:\n",
    "        partn = text[0].text\n",
    "        partn = re.sub(r'(Университет–партнер)|(Университеты–партнеры)|(Программа создана совместно с)', '', partn)\n",
    "    return partn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Важные объявления**\n",
    "\n",
    "В стандарте указано, что должно быть не более 3 объявлений, содержащих гиперссылку, а также не более 70 символов с пробелами. Соответсвенно, для каждой ОП создадим два столбца: \n",
    "- Список гиперссылок; \n",
    "- Список количеств символов в каждом объявлении, если более 3 объявлений, то \"Больше 3х\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Важные объявления\n",
    "\n",
    "def announcement(tag, attribute, soup):\n",
    "    text = soup.findAll(tag, {\"class\": attribute})\n",
    "    if len(text) == 0:\n",
    "        urls = 'Нет'\n",
    "        number_ann = 'Нет'\n",
    "    else:\n",
    "        urls = []\n",
    "        number_ann = []\n",
    "        for i in range(len(text)):\n",
    "            url = text[i].contents[0].get('href')\n",
    "            if (url is None) or (url == ''):\n",
    "                urls.append('Нет')\n",
    "            else:\n",
    "                urls.append(url)\n",
    "            number_ann.append(len(text[i].text))\n",
    "        if len(number_ann) > 3:\n",
    "            urls = 'Больше 3х'\n",
    "            number_ann = 'Больше 3х'\n",
    "    return [urls, number_ann]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Текст о программе\n",
    "\n",
    "def about(tag, attribute, soup):\n",
    "    text = soup.findAll(tag, {\"class\": attribute})\n",
    "    if len(text) == 0:\n",
    "        return 'Нет'\n",
    "    else:\n",
    "        return len(text[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Новости\n",
    "\n",
    "def news(soup):\n",
    "    text = soup.findAll(\"div\", {\"class\": 'plate_news masonry'})\n",
    "    if text is None:\n",
    "        text = soup.findAll(\"div\", {\"class\": 'post-meta__date'})\n",
    "        if text is None:\n",
    "            return 'Нет'\n",
    "        else:\n",
    "            return 'Есть'\n",
    "    else:\n",
    "        return 'Есть'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Анонсы\n",
    "\n",
    "def events(tag, attribute1, attribute2, soup):\n",
    "    text = soup.findAll(tag, {\"class\": attribute1})\n",
    "    if text is None:\n",
    "        text = soup.findAll(tag, {\"class\": attribute2})\n",
    "        if text is None:\n",
    "            return 'Нет'\n",
    "        else:\n",
    "            return 'Есть'\n",
    "    else:\n",
    "        return 'Есть'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Основная функция для выгрузки основных разделов:\n",
    "\n",
    "soups_2 = []\n",
    "\n",
    "\n",
    "def main_info():\n",
    "\n",
    "    # Скопируем основную информацию из первой таблицы для быстрой навигации\n",
    "    result_2[['Наименование ОП', 'Уровень обучения',\n",
    "              'Подразделение', 'Ссылка на сайт']] = result[['Наименование ОП', 'Уровень обучения',\n",
    "                                                            'Подразделение', 'Ссылка на сайт']]\n",
    "\n",
    "    result_2['Продолжительность обучения'] = [duration(\"div\", 'with-indent2 b-row__item b-row__item--size_3 b-row__item--t6', soup) for soup in soups]\n",
    "\n",
    "    result_2['Форма обучения'] = [form(\"div\", 'with-indent2 b-row__item b-row__item--size_3 b-row__item--t6', soup) for soup in soups]\n",
    "\n",
    "    # Бюджетные и платные места\n",
    "    places = [budget_paid(\"div\", 'with-indent2 b-row__item b-row__item--size_3 b-row__item--t6', soup) for soup in soups]\n",
    "    places = np.transpose(places)\n",
    "    result_2['Бюджетные места'] = places[0]\n",
    "    result_2['Платные места'] = places[1]\n",
    "\n",
    "    result_2['Аккредитация'] = [accred(\"div\", 'with-indent2 b-row__item b-row__item--size_3 b-row__item--t6', soup) for soup in soups]\n",
    "\n",
    "    result_2['Аннотация (кол-во знаков)'] = [annot(\"div\", 'with-indent lead-in _builder builder--text', 'g larger', soup) for soup in soups]\n",
    "    \n",
    "    result_2['Партнеры'] = [partns(\"div\", 'b-stroke b-stroke--partners', soup) for soup in soups]\n",
    "\n",
    "    # Важные объявления\n",
    "    announc = [announcement(\"div\", 'head-news__text', soup) for soup in soups]\n",
    "    announc = np.transpose(announc)\n",
    "    result_2['Ссылки на объявления'] = announc[0]\n",
    "    result_2['Кол-во символов в объявлениях'] = announc[1]\n",
    "\n",
    "    # Текст о программе\n",
    "    urls = result['Ссылка на сайт']\n",
    "    urls = urls + 'about/'\n",
    "    for url in urls:\n",
    "        html = rq.get(url).text\n",
    "        soups_2.append(soup_d(html))\n",
    "    result_2['Текст о программе (кол-во знаков)'] = [about(\"div\", 'post__text', soup) for soup in soups_2]\n",
    "\n",
    "    result_2['Новости'] = [news(soup) for soup in soups]\n",
    "\n",
    "    result_2['Анонсы'] = [events(\"div\", 'g-day__text', 'h5', soup) for soup in soups]\n",
    "\n",
    "    # Запишем файл\n",
    "    result_2.to_excel(\"Основные разделы.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Раздел \"Главное\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_3 = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def info(lst, newlst, links, linkss, v = 0):\n",
    "    for i in lst:\n",
    "        if i in links:\n",
    "            for q in range(len(links)):\n",
    "                if links[q] == i:\n",
    "                    if linkss[q] in newlst:\n",
    "                        pass\n",
    "                    elif v == 1:\n",
    "                        pass\n",
    "                    else:\n",
    "                        if linkss[q] is None:\n",
    "                            newlst.append('Нет')\n",
    "                        else:\n",
    "                            newlst.append(linkss[q])\n",
    "                        v = 1\n",
    "                        break\n",
    "        if i == lst[-1]:\n",
    "            if v == 0:\n",
    "                newlst.append('Нет')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "infblock = []\n",
    "about = []\n",
    "partners = []\n",
    "success = []\n",
    "alumni = []\n",
    "seminar = []\n",
    "projects = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def glavnoe():\n",
    "\n",
    "    result_3[['Наименование ОП', 'Уровень обучения', 'Подразделение', 'Ссылка на сайт']] = result[[\n",
    "        'Наименование ОП', 'Уровень обучения', 'Подразделение', 'Ссылка на сайт']]\n",
    "\n",
    "    for z in range(len(soups)):\n",
    "        block = soups[z].findAll('li', {'class': 'fa-sidemenu__item'})\n",
    "        links = [i.contents[0].contents for i in block]\n",
    "        linkss = [i.contents[0].get('href') for i in block]\n",
    "\n",
    "        if soups[z].find('div', {'class': 'fa-sidemenu__header'}).contents[0].contents == ['О программе']:\n",
    "            about.append(result_3['Ссылка на сайт'][z])\n",
    "        else:\n",
    "            about.append('Нет')\n",
    "\n",
    "        partnerss = [['Партнеры '], ['Партнеры'], ['Партнеры и работодатели'], ['Наши партнеры'], [\n",
    "            'Компании-партнеры'],  ['Эксперты - партнеры программы'], ['Попечительский совет и партнеры программы']]\n",
    "        info(partnerss, partners, links, linkss)\n",
    "\n",
    "        successs = [['Достижения студентов'], ['Достижения магистрантов']]\n",
    "        info(successs, success, links, linkss)\n",
    "\n",
    "        alumnis = [['Наши выпускники'], ['Выпускники']]\n",
    "        info(alumnis, alumni, links, linkss)\n",
    "\n",
    "        seminars = [['Научно-исследовательский семинар (НИС)'], ['НИС'], ['Научно-исследовательский семинар'], ['На\\xadуч\\xadно-ис\\xadсле\\xadдо\\xadва\\xadтель\\xadский семинар'], [\n",
    "            'Научный семинар'], ['Проектно-исследовательский семинар'], ['Проектный семинар'], ['Концепция научно- исследовательского семинара']]\n",
    "        info(seminars, seminar, links, linkss)\n",
    "\n",
    "        projectss = [['Проектная и исследовательская работа'], ['Проектная работа (на 2 и 3 курсе)'], ['Проектная работа'], ['Проектная деятельность'], ['Проектная деятельность'], ['Проекты'], ['Проекты и проектный семинар'], [\n",
    "            'Проекты студентов'], ['Проекты и клубы студентов'], ['Проекты магистрантов'], ['Проекты и Проектный семинар'], ['Проекты и проектная работа'], ['Проекты и исследовательская работа'], ['Проекты и исследовательская деятельность']]\n",
    "        info(projectss, projects, links, linkss)\n",
    "\n",
    "    result_3['О программе'] = about\n",
    "    result_3['Партнеры'] = partners\n",
    "    result_3['Достижения студентов'] = success\n",
    "    result_3['Выпускники'] = alumni\n",
    "    result_3['НИС'] = seminar\n",
    "    result_3['Проектная работа'] = projects\n",
    "\n",
    "    # Запишем файл\n",
    "    result_3.to_excel(\"Раздел 'Главное'.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "glavnoe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Раздел Абитуриентам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_4 = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "future = []\n",
    "adm = []\n",
    "prepare = []\n",
    "infblock2 = []\n",
    "passport = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "soups_4 = []\n",
    "\n",
    "\n",
    "def abit():\n",
    "\n",
    "    result_4[['Наименование ОП', 'Уровень обучения', 'Подразделение']] = result[[\n",
    "        'Наименование ОП', 'Уровень обучения', 'Подразделение']]\n",
    "\n",
    "    urls_abit = [url + 'admission/' for url in result['Ссылка на сайт']]\n",
    "    result_4['Ссылка на раздел абитуриентам'] = urls_abit\n",
    "\n",
    "    # Теперь найдем soup\n",
    "    for url in urls_abit:\n",
    "        html = rq.get(url).text\n",
    "        soups_4.append(soup_d(html))\n",
    "\n",
    "    for z in range(len(soups_4)):\n",
    "        block = soups_4[z].findAll(\n",
    "            'a', {'class': 'link link_no-underline link_dark2 fa-sidemenu__link'})\n",
    "        links = [i.contents for i in block]\n",
    "        linkss = [i.get('href') for i in block]\n",
    "\n",
    "        if links == []:\n",
    "            infblock2.append('Нет')\n",
    "        else:\n",
    "            try:\n",
    "                infblock2.append(soups_4[z].find('a', {\n",
    "                                 'class': 'link link_no-underline link_dark2 selected fa-sidemenu__link selected'}).get('href'))\n",
    "            except AttributeError:\n",
    "                infblock2.append('Нет')\n",
    "\n",
    "        try:\n",
    "            if soups_4[z].find('a', {'class': 'link link_no-underline link_dark2 selected fa-sidemenu__link selected'}).contents == ['Паспорт программы']:\n",
    "                passport.append(soups_4[z].find('a', {\n",
    "                                'class': 'link link_no-underline link_dark2 selected fa-sidemenu__link selected'}).get('href'))\n",
    "            else:\n",
    "                passport.append('Нет')\n",
    "        except AttributeError:\n",
    "            try:\n",
    "                if soups_4[z].find('h3').contents == ['Паспорт программы']:\n",
    "                    passport.append(soups_4[z].find('a', {\n",
    "                                    'class': 'link link_no-underline link_dark2 fa-sidemenu__link selected'}).get('href'))\n",
    "                else:\n",
    "                    passport.append('Нет')\n",
    "            except AttributeError:\n",
    "                passport.append('Нет')\n",
    "\n",
    "        futuree = [['Будущая профессия'], ['Будущая профессия ']]\n",
    "        info(futuree, future, links, linkss)\n",
    "\n",
    "        admm = [['Траектории поступления'], ['Траектории поступления иностранных граждан'], [\n",
    "            'Траектории поступления для иностранных абитуриентов']]\n",
    "        info(admm, adm, links, linkss)\n",
    "\n",
    "        preparee = [['Подготовка'], ['Подготовка к поступлению']]\n",
    "        info(preparee, prepare, links, linkss)\n",
    "\n",
    "    result_4['Информационный блок'] = infblock2\n",
    "    result_4['Паспорт программы'] = passport\n",
    "    result_4['Будущая профессия'] = future\n",
    "    result_4['Траектории поступления'] = adm\n",
    "    result_4['Подготовка'] = prepare\n",
    "\n",
    "    # Запишем файл\n",
    "    result_4.to_excel(\"Абитуриентам.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "abit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Раздел Студентам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_5 = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "infblock3 = []\n",
    "ratings = []\n",
    "mobility = []\n",
    "prac = []\n",
    "diplomas = []\n",
    "theses = []\n",
    "assess = []\n",
    "moocs = []\n",
    "trc = []\n",
    "inn = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "soups_5 = []\n",
    "\n",
    "\n",
    "def students():\n",
    "\n",
    "    # Скопируем основную информацию из первой таблицы для быстрой навигации\n",
    "    result_5[['Наименование ОП', 'Уровень обучения', 'Подразделение']] = result[[\n",
    "        'Наименование ОП', 'Уровень обучения', 'Подразделение']]\n",
    "\n",
    "    urls_stud = [url + 'students/' for url in result['Ссылка на сайт']]\n",
    "    result_5['Ссылка на раздел студентам'] = urls_stud\n",
    "\n",
    "    # Теперь найдем soup Студентам\n",
    "    for url in urls_stud:\n",
    "        html = rq.get(url).text\n",
    "        soups_5.append(soup_d(html))\n",
    "\n",
    "    for i in range(len(soups_5)):\n",
    "        block = soups_5[i].findAll(\n",
    "            'a', {'class': 'link link_no-underline link_dark2 fa-sidemenu__link'})\n",
    "        links = [j.contents for j in block]\n",
    "        linkss = [k.get('href') for k in block]\n",
    "\n",
    "        if links == []:\n",
    "            infblock3.append('Нет')\n",
    "        else:\n",
    "            try:\n",
    "                infblock3.append(soups_5[i].find('a', {\n",
    "                    'link link_no-underline link_dark2 selected fa-sidemenu__link selected'}).get('href'))\n",
    "            except AttributeError:\n",
    "                infblock3.append('Нет')\n",
    "\n",
    "        ratingss = [['Рейтинги'], ['Рейтинги '], [\n",
    "            'Рейтинги студентов'], ['Рейтинг студентов'], ['Рейтинг']]\n",
    "        info(ratingss, ratings, links, linkss)\n",
    "\n",
    "        mobilityy = [['Студенческая мобильность'], ['Академическая мобильность'], ['Академическая мобильность студентов'], [\n",
    "            'Международная академическая мобильность'], ['Внутриуниверситетская мобильность'], ['Международная мобильность']]\n",
    "        info(mobilityy, mobility, links, linkss)\n",
    "\n",
    "        pracs = [['Стажировки и практика'], ['Археологическая практика'], ['Музейная практика'], ['Архивная практика'], ['Учебная практика (1 курс)'], ['Производственная практика (3 курс)'], ['Преддипломная практика'], ['Проектная деятельность и преддипломная практика'], [\n",
    "            'Производственная научно-исследовательская практика'], ['Практика и научно-исследовательская работа'], ['Практика'], ['Практика, проектная и исследовательская работа'], ['Практика, курсовые и ВКР'], ['Практика и проектная деятельность'],  ['Практика и проекты'], ['Практика 1 курса'], ['Практика и проекты 2 курса']]\n",
    "        info(pracs, prac, links, linkss)\n",
    "\n",
    "        diplomass = [['Каталог ВКР'], ['ВКР']]\n",
    "        info(diplomass, diplomas, links, linkss)\n",
    "\n",
    "        thesess = [['Практика, курсовые и ВКР'], ['Курсовые и ВКР'], ['Курсовые работы'], ['Курсовые'], [\n",
    "            'Курсовые и выпускные квалификационные работы (ВКР)'], ['Курсовые работы и ВКР'], ['Курсовые и выпускные квалификационные работы'], ['Курсовые и проекты']]\n",
    "        info(thesess, theses, links, linkss)\n",
    "\n",
    "        assesss = [['Итоговая аттестация'], ['Итоговая аттестация '], ['Государственная итоговая аттестация'], ['Государственная итоговая аттестация '], [\n",
    "            'ВКР и Итоговая аттестация'], ['Итоговая аттестация (Защита ВКР)'], ['Защита ВКР (Итоговая аттестация)']]\n",
    "        info(assesss, assess, links, linkss)\n",
    "\n",
    "        mooc = [['Рекомендованные онлайн-курсы'], ['Рекомендованные онлайн-курсы (MOOC)'], ['MOOC (онлайн курсы)'], [\n",
    "            'Рекомендованные онлайн курсы'], [\"MOOC's (онлайн курсы)\"], ['Список рекомендованных онлайн курсов'], ['Курсы MOOC']]\n",
    "        info(mooc, moocs, links, linkss)\n",
    "\n",
    "        if ['Выбор траектории обучения'] in links:\n",
    "            trc.append('https://electives.hse.ru')\n",
    "        else:\n",
    "            trc.append('Нет')\n",
    "\n",
    "        if ['Дополнительные иностранные языки'] in links:\n",
    "            inn.append('https://busedu.hse.ru/inn')\n",
    "        else:\n",
    "            inn.append('Нет')\n",
    "\n",
    "    result_5['Информационный блок'] = infblock3\n",
    "    result_5['Рейтинги'] = ratings\n",
    "    result_5['Студенческая мобильность'] = mobility\n",
    "    result_5['Практика'] = prac\n",
    "    result_5['Каталог ВКР'] = diplomas\n",
    "    result_5['Курсовые и ВКР'] = theses\n",
    "    result_5['Итоговая аттестация'] = assess\n",
    "    result_5['Рекомендованные онлайн-курсы'] = moocs\n",
    "    result_5['Выбор траектории обучения'] = trc\n",
    "    result_5['Дополнительные иностранные языки'] = inn\n",
    "\n",
    "    # Запишем файл\n",
    "    result_5.to_excel(\"Студентам.xlsx\")\n",
    "\n",
    "    print('Проверка всех пунктов Стандарта завершена')\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Проверка всех пунктов Стандарта завершена\n",
      "--- 2226.217045068741 seconds ---\n"
     ]
    }
   ],
   "source": [
    "students()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Подсчет количества знаков на всех страницах** (самая долгая функция)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = rq.utils.default_headers()\n",
    "headers['User-Agent'] = 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36'\n",
    " \n",
    "def amount(url):\n",
    "    if url == 'Нет':\n",
    "        return 'Нет'\n",
    "    else:\n",
    "        html = rq.get(url, headers=headers).text\n",
    "        soup = soup_d(html)\n",
    "        return len(soup.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "amount_counter = pd.DataFrame()\n",
    "amount_counter[['Наименование ОП', 'Уровень обучения', 'Подразделение', 'Ссылка на сайт']] = result[[\n",
    "        'Наименование ОП', 'Уровень обучения', 'Подразделение', 'Ссылка на сайт']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 3371.40043592453 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Общие разделы\n",
    "amount_counter['Учебные курсы'] = [amount(url) for url in result['Учебные курсы']]\n",
    "amount_counter['Преподаватели'] = [amount(url) for url in result['Преподаватели']]\n",
    "amount_counter['Число студентов и вакантные места'] = [amount(url) for url in result['Число студентов и вакантные места']]\n",
    "amount_counter['Документы образовательной программы'] = [amount(url) for url in result['Документы образовательной программы']]\n",
    "amount_counter['Расписание'] = [amount(url) for url in result['Расписание']]\n",
    "amount_counter['День открытых дверей'] = [amount(url) for url in result['День открытых дверей']]\n",
    "amount_counter['Академический совет'] = [amount(url) for url in result['Академический совет']]\n",
    "amount_counter['Академический руководитель'] = [amount(url) for url in result['Академический руководитель']]\n",
    "amount_counter['Менеджер'] = [amount(url) for url in result['Менеджер']]\n",
    "amount_counter['Учебный офис'] = [amount(url) for url in result['Учебный офис']]\n",
    "\n",
    "# Основные разделы\n",
    "# Количество знаков \"О программе\" посчитано в Общих разделах, а в Разделе Главное есть ссылки\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1374.985915184021 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Раздел Главное\n",
    "amount_counter['Партнеры'] = [amount(url) for url in result_3['Партнеры']]\n",
    "amount_counter['Достижения студентов'] = [amount(url) for url in result_3['Достижения студентов']]\n",
    "amount_counter['Выпускники'] = [amount(url) for url in result_3['Выпускники']]\n",
    "amount_counter['НИС'] = [amount(url) for url in result_3['НИС']]\n",
    "amount_counter['Проектная работа'] = [amount(url) for url in result_3['Проектная работа']]\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 2115.44477891922 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Абитуриентам\n",
    "amount_counter['Информационный блок Абитуриентам'] = [amount(url) for url in result_4['Информационный блок']]\n",
    "amount_counter['Паспорт программы'] = [amount(url) for url in result_4['Паспорт программы']]\n",
    "amount_counter['Будущая профессия'] = [amount(url) for url in result_4['Будущая профессия']]\n",
    "amount_counter['Траектории поступления'] = [amount(url) for url in result_4['Траектории поступления']]\n",
    "amount_counter['Подготовка'] = [amount(url) for url in result_4['Подготовка']]\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 3075.8569781780243 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Студентам\n",
    "amount_counter['Информационный блок Студентам'] = [amount(url) for url in result_5['Информационный блок']]\n",
    "amount_counter['Рейтинги'] = [amount(url) for url in result_5['Рейтинги']]\n",
    "amount_counter['Студенческая мобильность'] = [amount(url) for url in result_5['Студенческая мобильность']]\n",
    "amount_counter['Практика'] = [amount(url) for url in result_5['Практика']]\n",
    "amount_counter['Каталог ВКР'] = [amount(url) for url in result_5['Каталог ВКР']]\n",
    "amount_counter['Курсовые и ВКР'] = [amount(url) for url in result_5['Курсовые и ВКР']]\n",
    "amount_counter['Итоговая аттестация'] = [amount(url) for url in result_5['Итоговая аттестация']]\n",
    "amount_counter['Рекомендованные онлайн-курсы'] = [amount(url) for url in result_5['Рекомендованные онлайн-курсы']]\n",
    "amount_counter['Выбор траектории обучения'] = [amount(url) for url in result_5['Выбор траектории обучения']]\n",
    "amount_counter['Дополнительные иностранные языки'] = [amount(url) for url in result_5['Дополнительные иностранные языки']]\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "amount_counter.to_excel('Количество знаков.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
